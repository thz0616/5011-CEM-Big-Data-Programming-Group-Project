{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-06T01:54:13.005783Z",
     "start_time": "2025-11-06T01:54:12.465322Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ===== thresholds (tune as needed) =====\n",
    "target_corr_threshold = 0.30   # keep features with |corr(feature, Target)| >= this\n",
    "feature_corr_threshold = 0.95  # drop a feature if it's > this correlated with any selected feature\n",
    "\n",
    "# ===== IO =====\n",
    "in_path  = \"data/dropoutgraduate.csv\"                 # change if needed\n",
    "out_path = \"data/ExtractedP.csv\"   # Target will be last/right-most column"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T01:57:20.624916Z",
     "start_time": "2025-11-06T01:57:20.582285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Load =====\n",
    "df = pd.read_csv(in_path, sep=\";\")\n",
    "logs = []  # only log when an action actually happens"
   ],
   "id": "dfe9fc7a0dfc2af",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T01:59:04.332443Z",
     "start_time": "2025-11-06T01:59:04.305946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Step 1: Locate / sanitize Target =====\n",
    "target_col = next((c for c in df.columns if c.strip().lower() == \"target\"), None)\n",
    "if target_col is None:\n",
    "    raise KeyError(\"Couldn't find a 'Target' column (case-insensitive).\")\n",
    "\n",
    "y_raw = df[target_col]\n",
    "y_num = pd.to_numeric(y_raw, errors=\"coerce\")\n",
    "\n",
    "# Map non-numeric labels to numeric codes if present\n",
    "if y_num.isna().any():\n",
    "    label_to_code = {\"dropout\": 0, \"graduate\": 1, \"enrolled\": 2}\n",
    "    mapped = y_raw.astype(str).str.strip().str.lower().map(label_to_code)\n",
    "    n_mapped = mapped.notna().sum()\n",
    "    if n_mapped > 0:\n",
    "        logs.append(f\"[Step 1] Detected non-numeric Target values. Mapped labels to codes for {int(n_mapped)} rows.\")\n",
    "        y_num = mapped\n",
    "\n",
    "# Fail if unknown remain\n",
    "if y_num.isna().any():\n",
    "    unknown = sorted(pd.Series(y_raw[y_num.isna()].unique()).astype(str).tolist())\n",
    "    raise ValueError(f\"[Step 1] Unrecognized Target values: {unknown}. Please clean them first.\")\n",
    "\n",
    "df[target_col] = y_num.astype(int)\n",
    "\n",
    "# Keep only binary {0,1} for point-biserial context; drop class 2 if present\n",
    "n_before = len(df)\n",
    "df = df[df[target_col].isin([0, 1])].copy()\n",
    "removed = n_before - len(df)\n",
    "if removed > 0:\n",
    "    logs.append(f\"[Step 1] Removed {removed} rows with Target=2 to keep a binary target (0/1).\")\n",
    "\n",
    "y = df[target_col].astype(int)"
   ],
   "id": "d2b72fe25271f479",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T02:10:36.679490Z",
     "start_time": "2025-11-06T02:10:36.647662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Step 2: Feature encoding & cleaning =====\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "X_enc = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Log dummy count (if any)\n",
    "enc_total = X_enc.shape[1]\n",
    "orig_num = len(num_cols)\n",
    "dummy_added = enc_total - orig_num\n",
    "if dummy_added > 0:\n",
    "    logs.append(f\"[Step 2] One-hot encoded {len(cat_cols)} categorical column(s), added {dummy_added} dummy feature(s).\")\n",
    "\n",
    "# Replace ±inf with NaN\n",
    "inf_count = int(np.isinf(X_enc.select_dtypes(include=[np.number]).to_numpy()).sum()) if enc_total > 0 else 0\n",
    "if inf_count > 0:\n",
    "    logs.append(f\"[Step 2] Found {inf_count} ±inf value(s); replaced with NaN.\")\n",
    "    X_enc = X_enc.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill NaNs with column medians\n",
    "nan_before = int(X_enc.isna().sum().sum())\n",
    "if nan_before > 0:\n",
    "    logs.append(f\"[Step 2] Detected {nan_before} missing value(s); filled with column medians.\")\n",
    "    X_enc = X_enc.fillna(X_enc.median(numeric_only=True))\n",
    "\n",
    "# Drop constant columns\n",
    "const_cols = X_enc.columns[X_enc.nunique() <= 1].tolist()\n",
    "if const_cols:\n",
    "    preview = \", \".join(const_cols[:10]) + (\"…\" if len(const_cols) > 10 else \"\")\n",
    "    logs.append(f\"[Step 2] Dropped {len(const_cols)} constant column(s): {preview}\")\n",
    "    X_enc = X_enc.drop(columns=const_cols)\n",
    "\n",
    "if X_enc.shape[1] == 0:\n",
    "    raise ValueError(\"[Step 2] No usable (non-constant) features after encoding/cleaning.\")"
   ],
   "id": "eed84fbc573aa9db",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T02:11:01.364649Z",
     "start_time": "2025-11-06T02:11:01.361173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Print preprocessing log =====\n",
    "print(\"=== Preprocessing Log ===\")\n",
    "if logs:\n",
    "    for m in logs:\n",
    "        print(m)\n",
    "else:\n",
    "    print(\"No actions were performed in Step 1 and Step 2.\")\n",
    "print(\"=== End of Log ===\\n\")"
   ],
   "id": "2c249739dca53c2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Preprocessing Log ===\n",
      "No actions were performed in Step 1 and Step 2.\n",
      "=== End of Log ===\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T02:14:27.159889Z",
     "start_time": "2025-11-06T02:14:27.131618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Step 3: Pearson correlation vs Target =====\n",
    "corr_with_target = X_enc.apply(lambda s: s.corr(y))  # equals point-biserial for binary y\n",
    "corr_df = (\n",
    "    pd.DataFrame({\"feature\": X_enc.columns, \"r\": corr_with_target.values})\n",
    "    .assign(abs_r=lambda d: d[\"r\"].abs())\n",
    "    .sort_values(\"abs_r\", ascending=False)\n",
    ")\n",
    "\n",
    "print(f\"Total usable features: {X_enc.shape[1]}\")\n",
    "print(\"Top 15 by |r(Target)|:\")\n",
    "print(corr_df[[\"feature\", \"r\"]].head(15).to_string(index=False))"
   ],
   "id": "92d29d99bd41b64e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usable features: 36\n",
      "Top 15 by |r(Target)|:\n",
      "                               feature         r\n",
      "   Curricular units 2nd sem (approved)  0.653995\n",
      "      Curricular units 2nd sem (grade)  0.605350\n",
      "   Curricular units 1st sem (approved)  0.554881\n",
      "      Curricular units 1st sem (grade)  0.519927\n",
      "               Tuition fees up to date  0.442138\n",
      "                    Scholarship holder  0.313018\n",
      "                     Age at enrollment -0.267229\n",
      "                                Debtor -0.267207\n",
      "                                Gender -0.251955\n",
      "                      Application mode -0.244507\n",
      "   Curricular units 2nd sem (enrolled)  0.182897\n",
      "   Curricular units 1st sem (enrolled)  0.161074\n",
      "                       Admission grade  0.128058\n",
      "                             Displaced  0.126113\n",
      "Curricular units 2nd sem (evaluations)  0.119239\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T02:19:52.141497Z",
     "start_time": "2025-11-06T02:19:52.127757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Step 4: Select by |r(Target)| and remove redundancy =====\n",
    "candidates = corr_df.loc[corr_df[\"abs_r\"] >= target_corr_threshold, \"feature\"].tolist()\n",
    "if len(candidates) == 0:\n",
    "    raise ValueError(f\"No features pass |r(Target)| >= {target_corr_threshold}. \"\n",
    "                     \"Lower target_corr_threshold or check preprocessing.\")\n",
    "\n",
    "X_cand = X_enc[candidates]\n",
    "corr_mat = X_cand.corr().abs()\n",
    "\n",
    "selected = []\n",
    "for feat in corr_df.loc[corr_df[\"feature\"].isin(candidates), \"feature\"]:\n",
    "    if all(corr_mat.loc[feat, s] <= feature_corr_threshold for s in selected):\n",
    "        selected.append(feat)\n",
    "\n",
    "if len(selected) == 0:\n",
    "    raise ValueError(f\"All candidates were removed by inter-feature correlation > {feature_corr_threshold}. \"\n",
    "                     \"Increase feature_corr_threshold.\")"
   ],
   "id": "f6d7674ae2e5e23a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T02:50:26.899847Z",
     "start_time": "2025-11-06T02:50:26.879547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Step 5: Save selected features + Target AS LAST COLUMN =====\n",
    "df_out = X_enc[selected].copy()\n",
    "df_out[target_col] = y.values  # append Target to the right-most position\n",
    "df_out.to_csv(out_path, sep=\";\", index=False, encoding=\"utf-8\")"
   ],
   "id": "134063100ed7c264",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T02:56:42.950788Z",
     "start_time": "2025-11-06T02:56:42.946993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== Summary =====\n",
    "print(\"\\n=== Selection Summary ===\")\n",
    "print(f\"Candidates by |r(Target)| ≥ {target_corr_threshold}: {len(candidates)}\")\n",
    "print(f\"Selected after redundancy filter (|corr| ≤ {feature_corr_threshold}): {len(selected)}\")\n",
    "print(f\"Saved CSV (features + Target as last column) -> {out_path}\")\n",
    "print(f\"First {len(selected)} selected features:\")\n",
    "print(pd.Series(selected[:20]).to_string(index=False))"
   ],
   "id": "9e0c1dc4bbc23d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Selection Summary ===\n",
      "Candidates by |r(Target)| ≥ 0.3: 6\n",
      "Selected after redundancy filter (|corr| ≤ 0.95): 6\n",
      "Saved CSV (features + Target as last column) -> data/ExtractedP.csv\n",
      "First 6 selected features:\n",
      "Curricular units 2nd sem (approved)\n",
      "   Curricular units 2nd sem (grade)\n",
      "Curricular units 1st sem (approved)\n",
      "   Curricular units 1st sem (grade)\n",
      "            Tuition fees up to date\n",
      "                 Scholarship holder\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
