{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-07T12:37:45.773115Z",
     "start_time": "2025-11-07T12:37:45.767978Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# --- TensorFlow / Keras ---\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "except ImportError as e:\n",
    "    raise ImportError(\n",
    "        \"TensorFlow is not installed. Please install it first, e.g.:\\n\"\n",
    "        \"  pip install tensorflow\\n\"\n",
    "        \"or\\n\"\n",
    "        \"  conda install -c conda-forge tensorflow\"\n",
    "    ) from e\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T12:40:06.548565Z",
     "start_time": "2025-11-07T12:40:06.544100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========= HYPERPARAMETERS (adjust here) =========\n",
    "learning_rate = 1e-3          # Adam learning rate\n",
    "epochs = 100                  # Max epochs (early stopping is used)\n",
    "batch_size = 512              # Batch size\n",
    "hidden_units = [256, 128]     # Hidden layer widths (add/remove/resize layers)\n",
    "dropout_rate = 0.30           # Dropout probability\n",
    "l2_reg = 0.0                  # L2 regularization factor (e.g., 0.0001)\n",
    "use_class_weight = True       # Use class weights for imbalanced data\n",
    "early_stopping_patience = 10  # Patience for early stopping\n",
    "reduce_lr_patience = 5        # Patience for reducing learning rate\n",
    "reduce_lr_factor = 0.5        # Factor to reduce learning rate by\n",
    "decision_threshold = 0.50     # Inference threshold (default 0.5)\n",
    "\n",
    "# Embedding dimension rule: dim = min(50, max(4, ceil(vocab_size^0.5)))\n",
    "def embedding_dim(vocab_size: int) -> int:\n",
    "    return int(min(50, max(4, np.ceil(vocab_size ** 0.5))))\n",
    "# ================================================"
   ],
   "id": "91a53d9cf64aa903",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T12:42:17.661920Z",
     "start_time": "2025-11-07T12:42:17.621266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 1) Load data ----------\n",
    "in_path = \"data/dropoutgraduate.csv\"\n",
    "df = pd.read_csv(in_path, sep=\";\")\n",
    "\n",
    "# Find Target column (case-insensitive)\n",
    "target_col = next((c for c in df.columns if c.strip().lower() == \"target\"), None)\n",
    "if target_col is None:\n",
    "    raise KeyError(\"Couldn't find a 'Target' column (case-insensitive).\")\n",
    "\n",
    "# Ensure binary target {0,1}; map labels if needed; drop any rows with class 2 if present\n",
    "y_num = pd.to_numeric(df[target_col], errors=\"coerce\")\n",
    "if y_num.isna().any():\n",
    "    print(\"Non-numeric target found, mapping 'Dropout'->0, 'Graduate'->1.\")\n",
    "    label_to_code = {\"dropout\": 0, \"graduate\": 1, \"enrolled\": 2}\n",
    "    y_num = df[target_col].astype(str).str.strip().str.lower().map(label_to_code)\n",
    "df[target_col] = y_num.astype(int)\n",
    "df = df[df[target_col].isin([0, 1])].copy()\n",
    "\n",
    "# Split features/labels\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(int).values\n",
    "\n",
    "# Identify column types\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "print(f\"Data loaded. Shape: {df.shape}\")\n",
    "print(f\"Numeric features: {len(numeric_cols)}\")\n",
    "print(f\"Categorical features: {len(categorical_cols)}\")"
   ],
   "id": "5d270922a88ed779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Shape: (3630, 37)\n",
      "Numeric features: 36\n",
      "Categorical features: 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T12:46:35.786907Z",
     "start_time": "2025-11-07T12:46:35.769556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 2) Train / test split (80/20 with stratify) ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ],
   "id": "c702ab76d6debd31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2904\n",
      "Test set size: 726\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T12:48:26.401828Z",
     "start_time": "2025-11-07T12:48:26.382437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 3) Preprocess: numeric impute+scale; categorical -> integer ids ----------\n",
    "# Numeric: fill NaN with train medians, then StandardScaler\n",
    "if numeric_cols:\n",
    "    num_medians = X_train[numeric_cols].median()\n",
    "    X_train_num = X_train[numeric_cols].copy().fillna(num_medians)\n",
    "    X_test_num  = X_test[numeric_cols].copy().fillna(num_medians)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "    X_test_num_scaled  = scaler.transform(X_test_num)\n",
    "    print(\"Numeric features scaled.\")\n",
    "else:\n",
    "    X_train_num_scaled = None\n",
    "    X_test_num_scaled = None\n",
    "\n",
    "# Categorical: build per-column vocab on TRAIN only; map to int ids (0=unknown)\n",
    "cat_mapping = {}\n",
    "cat_vocab_size = {}\n",
    "def build_mapping(series: pd.Series):\n",
    "    uniq = pd.Series(series.dropna().astype(str).unique())\n",
    "    mapping = {v: i+1 for i, v in enumerate(uniq)}  # 1..V; 0 reserved for unknown/missing\n",
    "    vocab_size = len(mapping) + 1\n",
    "    return mapping, vocab_size\n",
    "\n",
    "for col in categorical_cols:\n",
    "    m, V = build_mapping(X_train[col])\n",
    "    cat_mapping[col] = m\n",
    "    cat_vocab_size[col] = V\n",
    "\n",
    "def encode_categorical(df_part: pd.DataFrame, cols, mappings):\n",
    "    out = {}\n",
    "    for c in cols:\n",
    "        m = mappings[c]\n",
    "        arr = df_part[c].astype(str).map(m).fillna(0).astype(\"int32\").values  # unseen -> 0\n",
    "        out[c] = arr\n",
    "    return out\n",
    "\n",
    "if categorical_cols:\n",
    "    X_train_cat = encode_categorical(X_train, categorical_cols, cat_mapping)\n",
    "    X_test_cat  = encode_categorical(X_test,  categorical_cols, cat_mapping)\n",
    "    print(\"Categorical features encoded.\")\n",
    "else:\n",
    "    X_train_cat = {}\n",
    "    X_test_cat = {}"
   ],
   "id": "6640e9d4572439b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features scaled.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T12:50:58.929990Z",
     "start_time": "2025-11-07T12:50:58.840850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 4) Build Keras MLP with embeddings (Functional API) ----------\n",
    "inputs = []\n",
    "feats = []\n",
    "\n",
    "# numeric input\n",
    "if numeric_cols:\n",
    "    inp_num = layers.Input(shape=(len(numeric_cols),), name=\"num\")\n",
    "    inputs.append(inp_num)\n",
    "    feats.append(inp_num)\n",
    "\n",
    "# categorical inputs + embeddings\n",
    "for col in categorical_cols:\n",
    "    inp = layers.Input(shape=(1,), dtype=\"int32\", name=f\"cat_{col}\")\n",
    "    dim = embedding_dim(cat_vocab_size[col])\n",
    "    emb = layers.Embedding(input_dim=cat_vocab_size[col], output_dim=dim, name=f\"emb_{col}\")(inp)\n",
    "    emb = layers.Reshape((dim,), name=f\"reshape_{col}\")(emb)\n",
    "    inputs.append(inp)\n",
    "    feats.append(emb)\n",
    "\n",
    "# concatenate\n",
    "if len(feats) == 1:\n",
    "    x = feats[0]\n",
    "else:\n",
    "    x = layers.Concatenate(name=\"concat\")(feats)\n",
    "\n",
    "x = layers.BatchNormalization(name=\"bn0\")(x)\n",
    "\n",
    "for i, units in enumerate(hidden_units, start=1):\n",
    "    x = layers.Dense(units, activation=\"relu\",\n",
    "                     kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                     name=f\"dense{i}\")(x)\n",
    "    x = layers.BatchNormalization(name=f\"bn{i}\")(x)\n",
    "    x = layers.Dropout(dropout_rate, name=f\"drop{i}\")(x)\n",
    "\n",
    "out = layers.Dense(1, activation=\"sigmoid\", name=\"out\")(x)\n",
    "model = models.Model(inputs=inputs, outputs=out)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "id": "770c4030f966fd1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ num (\u001B[38;5;33mInputLayer\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m36\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn0 (\u001B[38;5;33mBatchNormalization\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m36\u001B[0m)             │           \u001B[38;5;34m144\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │         \u001B[38;5;34m9,472\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn1 (\u001B[38;5;33mBatchNormalization\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ drop1 (\u001B[38;5;33mDropout\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense2 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │        \u001B[38;5;34m32,896\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn2 (\u001B[38;5;33mBatchNormalization\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │           \u001B[38;5;34m512\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ drop2 (\u001B[38;5;33mDropout\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ out (\u001B[38;5;33mDense\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m129\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ num (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m44,177\u001B[0m (172.57 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,177</span> (172.57 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m43,337\u001B[0m (169.29 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,337</span> (169.29 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m840\u001B[0m (3.28 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">840</span> (3.28 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T12:55:47.646390Z",
     "start_time": "2025-11-07T12:55:47.632337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 5) Prepare model inputs ----------\n",
    "def pack_inputs(num_scaled, cat_dict):\n",
    "    inp = []\n",
    "    if numeric_cols:\n",
    "        inp.append(num_scaled.astype(\"float32\"))\n",
    "    for col in categorical_cols:\n",
    "        inp.append(cat_dict[col])\n",
    "    return inp\n",
    "\n",
    "train_inp = pack_inputs(X_train_num_scaled if numeric_cols else np.empty((len(X_train), 0)),\n",
    "                        X_train_cat)\n",
    "test_inp  = pack_inputs(X_test_num_scaled  if numeric_cols else np.empty((len(X_test), 0)),\n",
    "                        X_test_cat)\n",
    "\n",
    "# class weights (optional)\n",
    "class_weight = None\n",
    "if use_class_weight:\n",
    "    classes = np.array([0, 1])\n",
    "    weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "    class_weight = {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "    print(f\"Using class weights: {class_weight}\")\n",
    "\n",
    "# callbacks\n",
    "cbs = [\n",
    "    callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\",\n",
    "                            patience=early_stopping_patience, restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode=\"max\",\n",
    "                                patience=reduce_lr_patience, factor=reduce_lr_factor, min_lr=1e-6),\n",
    "]"
   ],
   "id": "27a9bf6856a259b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weights: {0: 1.2770448548812665, 1: 0.8217317487266553}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T12:59:11.317689Z",
     "start_time": "2025-11-07T12:59:10.372725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 6) Fit & evaluate ----------\n",
    "# NOTE: Using the test set for validation is for demonstration.\n",
    "# In a rigorous setting, you should create a separate validation set from the training data.\n",
    "history = model.fit(\n",
    "    train_inp, y_train,\n",
    "    validation_data=(test_inp, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")"
   ],
   "id": "76b52223e67db714",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9153 - auc: 0.9668 - loss: 0.2216 - val_accuracy: 0.8967 - val_auc: 0.9517 - val_loss: 0.2989 - learning_rate: 1.0000e-06\n",
      "Epoch 2/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9236 - auc: 0.9691 - loss: 0.2133 - val_accuracy: 0.8953 - val_auc: 0.9519 - val_loss: 0.2949 - learning_rate: 1.0000e-06\n",
      "Epoch 3/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9194 - auc: 0.9679 - loss: 0.2169 - val_accuracy: 0.8953 - val_auc: 0.9519 - val_loss: 0.2908 - learning_rate: 1.0000e-06\n",
      "Epoch 4/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9167 - auc: 0.9655 - loss: 0.2249 - val_accuracy: 0.8953 - val_auc: 0.9519 - val_loss: 0.2871 - learning_rate: 1.0000e-06\n",
      "Epoch 5/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9132 - auc: 0.9658 - loss: 0.2268 - val_accuracy: 0.8981 - val_auc: 0.9520 - val_loss: 0.2835 - learning_rate: 1.0000e-06\n",
      "Epoch 6/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9201 - auc: 0.9678 - loss: 0.2163 - val_accuracy: 0.8994 - val_auc: 0.9518 - val_loss: 0.2801 - learning_rate: 1.0000e-06\n",
      "Epoch 7/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9218 - auc: 0.9671 - loss: 0.2182 - val_accuracy: 0.9022 - val_auc: 0.9519 - val_loss: 0.2771 - learning_rate: 1.0000e-06\n",
      "Epoch 8/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9180 - auc: 0.9643 - loss: 0.2268 - val_accuracy: 0.9022 - val_auc: 0.9519 - val_loss: 0.2742 - learning_rate: 1.0000e-06\n",
      "Epoch 9/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9149 - auc: 0.9650 - loss: 0.2264 - val_accuracy: 0.9036 - val_auc: 0.9518 - val_loss: 0.2715 - learning_rate: 1.0000e-06\n",
      "Epoch 10/100\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9225 - auc: 0.9677 - loss: 0.2165 - val_accuracy: 0.9050 - val_auc: 0.9517 - val_loss: 0.2689 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:01:11.124255Z",
     "start_time": "2025-11-07T13:01:10.948771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate\n",
    "proba = model.predict(test_inp, batch_size=batch_size).ravel()\n",
    "pred  = (proba >= decision_threshold).astype(int)\n",
    "\n",
    "print(\"\\n--- Model Evaluation on Test Set ---\")\n",
    "print(\"Accuracy:\", f\"{accuracy_score(y_test, pred):.4f}\")\n",
    "try:\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    print(\"ROC-AUC:\", f\"{auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"ROC-AUC could not be computed:\", e)\n",
    "\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, pred, digits=4, target_names=[\"Dropout (0)\", \"Graduate (1)\"]))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, pred))"
   ],
   "id": "328b8b7582072c38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\n",
      "--- Model Evaluation on Test Set ---\n",
      "Accuracy: 0.8967\n",
      "ROC-AUC: 0.9520\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Dropout (0)     0.8693    0.8662    0.8677       284\n",
      "Graduate (1)     0.9142    0.9163    0.9153       442\n",
      "\n",
      "    accuracy                         0.8967       726\n",
      "   macro avg     0.8917    0.8912    0.8915       726\n",
      "weighted avg     0.8966    0.8967    0.8967       726\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[246  38]\n",
      " [ 37 405]]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:04:37.584824Z",
     "start_time": "2025-11-07T13:04:37.577754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- 7) Interactive inference ----------\n",
    "def infer_from_input(model, numeric_cols, categorical_cols, num_medians, scaler, cat_mapping):\n",
    "    \"\"\"\n",
    "    Prompts the user for a new student's data and makes a prediction.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Interactive Inference ---\")\n",
    "    print(\"Enter values for a NEW student (press Enter to use the training set median/default):\")\n",
    "    record_num = None\n",
    "    if numeric_cols:\n",
    "        record_num = []\n",
    "        for col in numeric_cols:\n",
    "            raw = input(f\"  > {col} (numeric): \")\n",
    "            if raw.strip() == \"\":\n",
    "                val = num_medians[col]\n",
    "            else:\n",
    "                try:\n",
    "                    val = float(raw)\n",
    "                except ValueError:\n",
    "                    print(f\"    Invalid input. Using median value for '{col}'.\")\n",
    "                    val = num_medians[col]\n",
    "            record_num.append(val)\n",
    "        record_num = np.array(record_num, dtype=\"float32\").reshape(1, -1)\n",
    "        record_num = scaler.transform(record_num).astype(\"float32\")\n",
    "\n",
    "    record_cat = {}\n",
    "    if categorical_cols:\n",
    "        for col in categorical_cols:\n",
    "            # Show up to 10 examples for context\n",
    "            examples = pd.Series(list(cat_mapping[col].keys()))[:10]\n",
    "            ex_str = \", \".join(map(str, examples))\n",
    "            raw = input(f\"  > {col} (categorical, e.g., {ex_str}): \")\n",
    "            key = raw.strip()\n",
    "            # Map the input to its integer ID, defaulting to 0 for unknown values\n",
    "            idx = cat_mapping[col].get(key, 0)\n",
    "            record_cat[col] = np.array([idx], dtype=\"int32\")\n",
    "\n",
    "    # Pack the processed inputs for the model\n",
    "    inp = []\n",
    "    if numeric_cols:\n",
    "        inp.append(record_num)\n",
    "    for col in categorical_cols:\n",
    "        inp.append(record_cat[col])\n",
    "\n",
    "    # Predict\n",
    "    p = float(model.predict(inp, verbose=0)[0, 0])\n",
    "    label = 1 if p >= decision_threshold else 0\n",
    "    label_map = {0: \"Dropout\", 1: \"Graduate\"}\n",
    "\n",
    "    print(\"\\n--- Prediction Result ---\")\n",
    "    print(f\"Predicted Status: {label_map[label]}\")\n",
    "    print(f\"Probability Graduate (class 1): {p:.4f}\")\n",
    "    print(f\"Probability Dropout (class 0): {1-p:.4f}\")"
   ],
   "id": "c9574eb06e0551bd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T13:07:29.622070Z",
     "start_time": "2025-11-07T13:07:18.027664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Call the function to start interactive inference\n",
    "infer_from_input(\n",
    "    model,\n",
    "    numeric_cols,\n",
    "    categorical_cols,\n",
    "    num_medians if numeric_cols else pd.Series(dtype=float),\n",
    "    scaler if numeric_cols else None,\n",
    "    cat_mapping\n",
    ")"
   ],
   "id": "6012fcf4aa8945ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Interactive Inference ---\n",
      "Enter values for a NEW student (press Enter to use the training set median/default):\n",
      "\n",
      "--- Prediction Result ---\n",
      "Predicted Status: Graduate\n",
      "Probability Graduate (class 1): 0.6422\n",
      "Probability Dropout (class 0): 0.3578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\tanho\\PycharmProjects\\5011 CEM Lab\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
